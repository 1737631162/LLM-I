# 例如GPT系列，为什么选用Decoder-Only的方式
```
理论上是因为Encoder的双向注意力会存在低秩问题，这可能会削弱模型表达能力
如果出现低秩现象，意味着：
  不同位置的注意力分布趋于线性相关（模型学到的特征之间存在高度相关性）；
  表达能力受限，难以捕捉复杂的模式；
  可能导致模型退化或性能下降。  

双向注意力导致低秩的核心原因  
（1）上下文信息的过度耦合，每个位置的表示同时依赖前后文
（2）训练目标与生成任务的矛盾，Encoder 的双向注意力常用于理解任务（目标是捕捉全局的语义信息），而非GPT这样的生成任务
（3）与因果注意力的对比：单向性对秩的保持，Decoder-only 架构（如 GPT）使用因果注意力（仅关注当前位置之前的信息），其注意力矩阵是下三角矩阵，这种非对称性避免了全局信息的过度耦合。
```

# 
